{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tc-wandering/twitter-sentiment-analysis/blob/main/twitter_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auj0mQb0cQoM"
      },
      "source": [
        "Sentiment analysis on Twitter classifies tweets (text) as positive or negative. We’ll use the Sentiment140 dataset (from Kaggle), which contains labeled tweets. Begin by installing needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmPf6ZX2cJRf",
        "outputId": "098ecb0b-3ddd-4d12-9d99-80ed68cf3230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72RPP47ucb3D"
      },
      "source": [
        "Load data: Download the Sentiment140 CSV (it’s often zipped as training.1600000.processed.noemoticon.csv.zip). Load it and keep only columns for polarity and text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsgFEfjEcbso",
        "outputId": "fc130b42-c49c-4f8a-d83a-98e0431088df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   polarity                                               text\n",
            "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1         0  is upset that he can't update his Facebook by ...\n",
            "2         0  @Kenichan I dived many times for the ball. Man...\n",
            "3         0    my whole body feels itchy and like its on fire \n",
            "4         0  @nationwideclass no, it's not behaving at all....\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/archive.zip',\n",
        "                 encoding='latin-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['polarity', 'text']\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-a3Dso5k-QU"
      },
      "source": [
        "Filter labels: Remove neutral tweets (polarity=2) and map labels 0→0 (negative), 4→1 (positive):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnH4TRTWk_Yi",
        "outputId": "7de49917-ff23-4e75-bbbe-3ce525217597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polarity\n",
            "0    800000\n",
            "1    800000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = df[df.polarity != 2]\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
        "print(df['polarity'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZkCP37ylBV1"
      },
      "source": [
        "Text preprocessing: A simple step is to lowercase the text. This matches clean_text function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIzTNfSElNmR",
        "outputId": "150193b1-13fd-4af3-eb47-833b26ab48ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
            "1  is upset that he can't update his Facebook by ...   \n",
            "2  @Kenichan I dived many times for the ball. Man...   \n",
            "3    my whole body feels itchy and like its on fire    \n",
            "4  @nationwideclass no, it's not behaving at all....   \n",
            "\n",
            "                                          clean_text  \n",
            "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
            "1  is upset that he can't update his facebook by ...  \n",
            "2  @kenichan i dived many times for the ball. man...  \n",
            "3    my whole body feels itchy and like its on fire   \n",
            "4  @nationwideclass no, it's not behaving at all....  \n"
          ]
        }
      ],
      "source": [
        "df['clean_text'] = df['text'].str.lower()\n",
        "print(df[['text','clean_text']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CApxfk_FlO-j"
      },
      "source": [
        "Train-test split: Split the data into training and test sets (80/20), this yields e.g. 1,280,000 train and 320,000 test tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJ0DcmjlZt4",
        "outputId": "a66795cb-9def-4606-e5aa-8ff3da20600c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1280000 Test size: 320000\n"
          ]
        }
      ],
      "source": [
        "X = df['clean_text']\n",
        "y = df['polarity']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWoWTztGltbN"
      },
      "source": [
        "Vectorization: Convert text to numeric features using TF-IDF. For speed, limit features to the top 5000 bigrams/unigrams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk0V4ZgWluL7",
        "outputId": "17ecb68c-f714-441a-adbb-ae136c6bb107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shape (train): (1280000, 5000)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnwFmUuelwF0"
      },
      "source": [
        "Model training: Train different classifiers and compare. For example, Bernoulli Naive Bayes, Linear SVM, and Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Isfaw905lx54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9f9031-50a2-44e6-f9d1-4b5a73d4f74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BernoulliNB Accuracy: 0.766478125\n",
            "SVM Accuracy: 0.79528125\n",
            "Logistic Regression Accuracy: 0.79539375\n"
          ]
        }
      ],
      "source": [
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_tfidf, y_train)\n",
        "bnb_pred = bnb.predict(X_test_tfidf)\n",
        "print(\"BernoulliNB Accuracy:\", accuracy_score(y_test, bnb_pred))\n",
        "\n",
        "svm = LinearSVC(max_iter=1000)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "svm_pred = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "\n",
        "logreg = LogisticRegression(max_iter=100)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "log_pred = logreg.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, log_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_bxgi7pl1oV"
      },
      "source": [
        "Sample predictions: Try your models on new example tweets: All models should output the same sentiment labels (1=positive, 0=negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NlnGXgh4l6_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72784135-7bfe-4821-e7b9-5b6520cb750a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BernoulliNB: [1 0 1]\n",
            "SVM: [1 0 1]\n",
            "Logistic: [1 0 1]\n"
          ]
        }
      ],
      "source": [
        "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
        "sample_vec = vectorizer.transform(sample_tweets)\n",
        "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
        "print(\"SVM:\", svm.predict(sample_vec))\n",
        "print(\"Logistic:\", logreg.predict(sample_vec))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkh7jTlZuvo7p+cl9QEIJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}